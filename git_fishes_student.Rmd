---
title: "Git, GitHub & Ocean Acidification"
author: "<Wing Tung Tsoi u7079953>"
date: "`r Sys.Date()`"
output: 
  bookdown::html_document2:
    code_folding: show
    number_sections: no
    toc: yes
    toc_depth: 6
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(digits=2)
```

# **Introduction**

This tutorial will draw on the skills you have already learnt on data visualisation, data wrangling and NHST to analyse a data set on ocean acidification effects on fish behaviour. However, we'll do that in the context of some new workflows that adopt Git and GitHub. 

Use this Rmarkdown file as your template to complete the tasks outlined within the instructions. There are questions asked in the instructions and here in the RMarkdown file. Answer these as best as you can to document your steps and thinking. There are also a series of coding exercises. 

Throughout we are also going to learn a bit more about how to format Rmarkdown documents. So, pay close attention to the formatting. We're also going to make use of the `bookdown` package now to render your Rmarkdown because, well, it's quite elegant in many ways. Before you start the tasks install the following packages:



# **Task 1**

### Provide the link to your GitHub Repo 

While the tasks are meant to get you familiar with how *GitHub* works you should try and make regular commits as you work your way through. We want to see how often you're using *Git*. Below, within the `()` brackets provide the link to your GitHub Repo. Just cut and paste it so we know what the repo name is and where it is. 

[My GitHub Repository]()

By adding the link in the `()` brackets it will hyperlink "My GitHub Repository". This is how to hyperlink in Rmarkdown documents.


# **Task 2**

This task involves cloning your repository on your computer. Where should we place this repository? While GitHub is somewhat of a cloud storage system because it's keeping record of your commits, files and changes in the cloud it is **not** a backup of your files (note that placing `**` around a word will bold it whereas `*` around a word will italicise it). The lack of *GitHub* being a file backup system is important to recognise! 

>**Question 1**: Why should you not rely on *GitHub* as a backup?

```{r, answer1, echo=TRUE, eval = FALSE}

Because if multiple people work on the file on the same time, it creates multiple versions of it, but could produce errors. It is a public repository as well, hence it is easy to lose workings. Others can edit the file so can be bad.

```

I'd usually suggest placing your repo in a cloud storage system like, *OneDrive*, *Dropbox*, or *GoogleDrive*. These will ensure that all your files are backed up and *GitHub* will provide a record of the detailed history. 

Before moving on you might have noticed that the code block above has a name `answer1` and I've added an argument `echo = TRUE`. It's good to label code blocks with useful names to help you debug when rendering of your document goes wrong (when, not IF!). These names need to all be unique. There are a whole bunch of arguments that you can list within code chunks that tell each chunk what to do. You can look to the great [Rmarkdown cheetsheet](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf) for more information.

>**Question 2**: In the second code block called `answer1` if we change echo = TRUE to echo = FALSE what will happen to the code block `answer1` when you render it?

```{r answer2, echo=TRUE, eval = TRUE}
Echo changes whether the code will be displayed alongside the results. If 'answer1' has echo=F, then it prevents code, but not the results from appearing in the finished file. This is a useful way to embed figures. There should not be any difference if echo changes for 'answer1' because there is no code.
```

**Important**: Notice that `eval = FALSE` for many code chunks. When you complete the tasks. Make sure to change these to `TRUE` otherwise you will find your code does not run!

# **Task 3**

Hopefully you have now successfully cloned down your *GitHub* repo. This is your new working directory from which your project will develop. 

Hopefully you also created and/or downloaded the following files and added them to your cloned repo:

1) created a new RStudio project file in your working directory
2) download the `OA_activitydat_20190302_BIOL3207.csv` from Wattle and add this to a `data/` folder in your repo 
3) Add the template Rmarkdown file, `git_fishes_student.Rmd` that was provided on wattle. You'll use this file to work through the tasks and answer questions. 

**STOP**: Before moving on, it's a good time to establish some good *GitHub* practices. You have just did an important step -- you added a bunch of new files. It's time stage these files and commit them so that you have a record. Use *GitHub Desktop* to do this. 

This is also a very good point to make sure that you understand relative path names fo coding. Wait, "relative what?". Your working directory can be considered the 'lowest' level of your project. The starting point, if you will. R needs to know where your files are that you want to load. Many people might be familiar with using the `setwd()` function to tell R where your files are that you need to load. This is problematic because everyone's path to a given working directory is different, and so, your code will not work on others' computers. Even across your own computers!

Lucky, RStudio project files take away the main issue by creating a project file that allows anyone to click on it to open the working directory to the same "spot". Having said that, if you start building structure (i.e., folders) in your working directory or repo than you need to understand how to navigate between folders to load and write files in the places that you want. 

Make sure you have added a `data/` folder to your working directory that you just cloned down. Think about how you would write some code to load in a data file that is within this folder. There are a few useful shortcuts you can use. For example, if you use `.` it means 'start from the current working directory'. That is the RStudio project file location if you click on a RStudio project. If you use `..` it means "start from the directory or folder one step back from the existing working directory".

>**Question 3**: **How would you write the path name to load in a data file from the data folder?**

Write your answer in the code chunk below:

```{r, loaddata, eval = FALSE, echo=TRUE}

path <- "./Files/OA_activitydat_20190302_BIOL3207.csv"
  
data <- read_csv(path)

```

Let's say that you added a new data folder that was inside an output folder (i.e., `output/data`) to your working directory. The purpose of this folder is to store and track your cleaned up data frame after you have done all your data wrangling and corrections. 

>**Question 4**: Using the `write_csv` function how would you write the path name to save this file to `output/data`?

```{r, write, eval = FALSE, echo=TRUE}

path <- "C:/Users/Denise Tsoi/OneDrive/Documents/GitHub/3207_Workshop_6"

write_csv(data, file = path)

```


# **Task 4**

We're ready for some coding! Lets do some coding and wrangling of the `OA_activitydat_20190302_BIOL3207.csv` data that we will use for the workshop. Note above, the `loaddata` code chunk should have already written the code to load the data file. At this point, we're assuming it's in your working space. If not, make sure you run the `loaddata` code chunk. 

First, write some code below to remove missing data

```{r, rmMiss}
data <- na.omit(data)
```

Second, drop out irrelevant columns and check that there are no spelling issues in `species` and `treatment`. Create a table of summary data that includes: 1) the mean, 2) the standard error and 3) the sample sizes of unique fish across ALL six fish species for each treatment. This will also help you detect any spelling errors. You can use the R package [`flextable`](https://ardata-fr.github.io/flextable-book/) to print out the results in a nice neat format! If you haven't heard about `flextable` spend 10 or so minutes having a look at it's functionality. It's incredible! You'll use this for tables throughout.

```{r summaryTab}
# Drop irrelevant columns
data_n <- subset(data, select = -c(...1, comment))
table(data_n$animal_id) #Found that there are some repeated animal IDs (Not unique)

# Check spelling in species and treatment but also generate a summary table

table(data$species) #Doesnt seem to have any spelling mistakes
table(data$treatment) #Doesnt seem to have any spelling mistakes

unique <- data_n[!duplicated(data_n[,"animal_id"]),] #Kept unique values
unique_g <- unique %>% group_by(species, treatment) %>% summarise(mean=mean(activity), 
                                                      n = length(activity), 
                                                      se = sd(activity) / sqrt(n))
  # Shows numerical information of unique animals

data_g <- data_n %>% group_by(species, treatment) %>% summarise(mean = mean(activity), 
                                                      n = length(activity), 
                                                      se = sd(activity) / sqrt(n))
  # Numerical information of animals excluding animal IDs

# Use flextable to render the summary table in a tidy format

library(flextable)

add_footer_lines(flextable(data_g), "Numeric information for all species")
add_footer_lines(flextable(unique_g), "Numeric information for unique species")
```

**STOP**: Before moving on, it's a good time to establish some good *GitHub* practices. You have just done an important step. It's time to save this file, stage it and commit it so that you have a record. Push these changes up using *GitHub Desktop*. It's important to do this frequently. It's probably not needed after every line of code, but it's good to do this when you have completed an important coding step. Of course, there's no harm in doing it more often. It will provide fine-scale tracking for you!

>**Question 5**: The new version of your Rmarkdown file should now be up on *GitHub*. In the browser window click on your most recent commit. Have a look at the file versioning system. You will notice two files side-by-side. Describe what you notice is being presented online. What do the red and green highlights mean?

```{r answer5, echo=TRUE, eval=FALSE}
## Write your answer here....remember to use '#" in front of your text.
```

# **Task 5**

Ignoring figures can be important because they take up quite a lot of space in your *GitHub* repo. For example, huge data files, or figures (e.g., png) can take up a tonne of space. We also might not need to save and track these because we can recreate them with our own code or re-download, process, save and track what we need. 

`.gitignore` files are used to control what *Git* tracks and what it ignores. You should have created a new folder path: `output/figures/`. Write some code now to create a pretty figure using ggplot that shows the difference between control and acidification treatments for each of the fish species in the data set:

```{r, prettyfig, fig.align='center', fig.cap="add a legend here"}
# ggplot figure showing mean activity for each treatment (Control, OA) for each species.


```

**Stretch Task**: The Clark et al. 2020 paper plots some pretty pictures on their figures. You have access to a folder called "pics/". Add the pics of the difference species from the "pics/" folder to your new plot. Explore the function `annotation_raster()` which might help you achieve this goal.

Note the code chunk used to make the figure. It has a `fig.cap` argument. That means Rmarkdown knows it's a figure and it will allow you to create a figure reference call. In other words, we can refer to our Figure \@ref(fig:prettyfig) by referring to the label for the chunk. This will automatically make a legend for us too (assuming you add one in). The same concept applied to Tables but the legend goes above these.

Now that you have the figure you may also want to write / save it as a separate file. Use `ggsave` function to save the figure(s) to your new `output/figures/`:

```{r, savefig}
# Use ggsave to save the figure

```

>**Question 6**: Given that you have added `output/figures/` to your `.gitignore` file describe what you notice about what you see in *GitHub Desktop*. 

```{r}
## Write your answer here
```

Last question for this task. I promise! It's important to think very carefully about what you track and ignore.

>**Question 7**: Assume that you added the `pics/` folder to your working directory to plot pictures of each fish on your figure. Do you want to track the files in the pic/ folder on GitHub despite them being .png files? Explain your reasoning. 

```{r, answer6}
## Add your answer here
```

# **Task 6**
This task involves teaming up with a collaborator. Exchange *GitHub* username details and add each other to your repo. Clone each others' repo on to your computer. Re-run their code. Does it work? If not, correct it for them. Explain to them WHY it didn't work. After all, they are right beside you! Think carefully about this. Will it still run on their computer if you have corrected it in a certain way?

Now, lets create a new figure in the code block below that simplifies the one produced in **Task 5**. Instead of all species, lets just plot three of the species (chromis, lemon, and acantho). In the figure code chunk make sure you add the necessary arguments (e.g., `fig.cap`) so that you can refer to Figure \@ref(fig:collabFig).

```{r, collabFig, echo=TRUE, eval=TRUE}
# You want to make changes to your collaborators figure in Task 5. Maybe you want to create a figure that focuses only on three fish species instead of the 5. More specifically, chromis, lemon, and acantho. Add code here to revise their figure to do that.
```


# **Task 7**
This task involves creating and resolving conflicts. Conflicts in files are denoted with specific markers. They look like this when you open a file with conflicts.

 <<<<<<<<< HEAD
  
  THIS IS YOUR CODE
  
 ==============
  
  THIS IS YOUR PARTNERS CODE
  
 !>>>>>>>>928731027301723

Resolving is easy. Decide on what changes you think are the best to proceed with and remove conflict markers. 

>**Stretch Task**: Try creating another conflict in the `collabFig` code chunk of the Rmarkdown file. Resolve the conflict again. More practice doing this is always good!

Once you have figured out how to create and solve conflicts it's time to update the README file with a little more detail about your project and the general workflow. The *GitHub* webpage uses the README file as a sort of introduction to the project. 

**Task**: Provide details about the workflow (i.e., which files are used, when and why) and write a detailed description of the data file used. Include the details about what the column means and which data file someone should use. 

Think about what you would need to know to make sure you can replicate a study. Provide these details so they are easy to find on the README.

# **Task 8**
There's not too much to do in this task on the coding front! You just need to create a *GitHub* issue and create a 'To Do' list on *GitHub* for you and your collaborator. 

# **Task 9**
Here, run some statistical tests to determine, for each species, whether the control vs high $CO^2$ treatments differ significantly from each other and in what direction. Provide the difference in means, their 95% confidence intervals, t-statistic, df and p-value. 

>**Stretch Task**: You can of course do this for each species seperately, but those who want a challenge, think about how you might use a loop or even some wrangling methods you have already learnt from the tidyverse to run these tests across all 6 species in a single block of code. If you're familiar with functions, you can even think about writing your own function! All these strategies will avoid having to copy and paste large chunks of code. If you're repeating anything, writing functions and loops are good ways to simplify.

```{r, stats, echo=TRUE, eval=TRUE}
# Add your code here
```

```{r, table1, echo=TRUE, eval=TRUE, tab.cap = "write a caption here"}
# Using the resulting object created above, which should be a table with all the summary statistics, t, df and p-value for each species create a table. Note that there is a tab.cap argument in the chunk arguments. Write a caption here. 
```

Now that you have a table, you can reference it within a document. For example, you can make a call to Table \@ref(tab:table1) by referring to the name of the code chunk. When you knit the html it will create a hyperlink to your table and insert a legend above the table for you. How cool is that!?

> **Question 8**: Pick one of your favorite species and write about the results to a reader. Write in the Rmarkdown file below what 1) the means and mean differences between control and acidification treatment is along with 2) the 95% confidence intervals of the difference

You can write your blurb below this. Before you do that, a few cool features of Rmarkdown. You can actually code in objects so that, when they are rendered they replace the inline code chunk with the result. To give you an example, an inline code chunk is written as follows: `r "add code here"`. When you render the document, whatever you place in the "add code here" section will be rendered. In this case, we are giving a string, so it simply just adds that in the place where the code is, render and see for yourself.  

Moving forward on that you can also add in an object and whatever that objects value is will also be spit out. For example, consider the following: `r x = 10; x`. What will happen? Well, it will place in the value 10 when rendered. Again, if you don't believe me, check for yourself by rendering the document. 

This is all **VERY** cool because that means if your code or data change than you can update your entire report very fast. It's also 100% reproducible. We know exactly where every single value in your report comes from. This is all pretty helpful when you want to check your code and report side-by-side. Now that you have a bit more detail fill in the following:

Mean activity for `r "species name here"` in the control group was `r "add code to place mean for control"` (s / min) compared to the OA treatment group, which was `r "mean for acidificaton treatment"` (s / min). The difference between control and OA treatment means was `r "code mean difference bw treatment"` (s / min) (95% CI: `r "code for lower CI"` to `r "code for upper CI"`). 

Now, using what you just learnt, describe what the null hypothesis being tested was and provide statistical evidence (t-statistic, df, and p-value) to support your conclusion about whether we can reject the null hypothesis. Again, make sure you use in-line code. Write you answer below:

**Write your answer here**


Re-analyse the data for a single species using permutations instead of a t-test. Do your results differ?

>**Stretch Task**:  If you really want a challenge try doing permutation tests for each species. Again, loops, functions or tidyverse (or even combinations might help). 

```{r, stretch2, echo=TRUE, eval=FALSE}
# Add your code here.
```

Below. Add a few sentences for the species (or multiple species) you talked about above to describe the permutation results:

**Add your text and inline code chunks here**

# **Task 10**

This is a stretch task on the use of *GitHub* and the challenges (or maybe lack of challenges) of reproducing others' work. If you finish the above tasks, then, have a crack at this one. See the html for details.




# **Installing packages**

This project focuses on utilising techniques such as data visualisation, data wrangling and NHST to analyse a data set on ocean acidification effects on fish behaviour.

```{r loadpacks, message=FALSE, results='hide'}

install.packages("pacman", repos = "http://cran.us.r-project.org") #p_load from 'pacman' package allows to seamlessly install many packages at once
library(pacman)

p_load(bookdown, tidyverse, ggforce, flextable, latex2exp, png, magick) # executes both 'install.packages' and library command

```


# **Establishing the path and working directory**

```{r, loaddata, eval = FALSE, echo=TRUE}

path <- "ANU things/Biol3207/3207_Workshop_6/Files/OA_activitydat_20190302_BIOL3207.csv"
  
data <- read_csv(path)

```


# **Data Wrangling**

```{r, rmMiss}
# Omitting missing data
data <- na.omit(data)
```

```{r summaryTab}
# Drop irrelevant columns ('...1' and 'comment')
data_n <- subset(data, select = -c(...1, comment))

# Checking the values within the 'animal_id' column
table(data_n$animal_id) #Found that there are some repeated animal IDs (Not unique)
unique <- data_n[!duplicated(data_n[,"animal_id"]),] #Kept unique values
unique_g <- unique %>% group_by(species, treatment) %>% summarise(mean=mean(activity), 
                                                      n = length(activity), 
                                                      se = sd(activity) / sqrt(n))
# Shows numerical information of unique fishes across all six fish species for each treatment

data_g <- data_n %>% group_by(species, treatment) %>% summarise(mean = mean(activity), 
                                                      n = length(activity), 
                                                      se = sd(activity) / sqrt(n))
difference <- data_g[3:5] - unique_g[3:5]
differences <- data.frame(data_g[1], data_g[2]) %>% cbind(difference)
# Numerical information of animals excluding animal IDs


library(flextable) # Use 'flextable' to render the summary table in a tidier format

flex_data <- add_footer_lines(flextable(data_g), "Numeric information for all species")
dlex_unique <- add_footer_lines(flextable(unique_g), "Numeric information for unique species")
flex_diff <- add_footer_lines(flextable(differences), "Numeric information for differences between all and unique species")

flex_data
dlex_unique
flex_diff
```

Tabling the animal IDs, we can see that some IDs are repeated, such as '71' and '274'. Those samples are omitted along with samples containing missing values to simplify the analysis and remain consistent.

'unique_g' and 'data_g' are numerical assessments for 'amount' of activity between control and elevated CO2 levels per fish species. The difference between the two exhibits the effect of duplicated (non-unique) on the data set, as shown by 'differences'. Standard error is a measure of data variation relative to sample size. In other words, quantifies how likely the sample mean represents the true population. Hence, the smaller the standard error, the more accurate our data set is. Because 'unique_g' only takes in unique data points, the sample size per group decreases, thus a large 'n' variation. This reflects the changes in mean and therefore, the overall decrease in standard error across all groups. 

Although 'data_g' shows more accuracy mathematically, 'unique_g' is still the preferred data set logically. Duplicated data points incurs experimental bias and errors that skews the result drastically. This is seen in 'differences' when groups like 'ancantho CO2' and 'humbug control' exhibits a large positive skew of the mean value (2.545 and 2.492) along with a large number of non-unique sample size (22 and 21). 'whitedams control' may have a small mean change (0.418) relative to sample size (37), but it has the highest change in standard error (-1.075), showing inconsistency and bias. 

Depending on the usage, different datasets will be used accordingly.

# **Data Visualisation**

```{r, figure1, fig.align='center', fig.cap="Figure 1: Mean activity of species and treatment"}
# ggplot figure showing mean activity for each treatment (Control, OA) for each species.
library(ggplot2)
ggplot(unique_g, aes(y = mean, x = species)) + geom_point(aes(colour = treatment)) + labs(title = "Figure 1: Mean activity of each species depending on the treatment", x = "Species", y = "Mean activity")

```
The figure above indicates the changes in fish activity according to levels of CO2 within the water. 'ancantho', 'chromis' and 'whitedams' tends to be more active under the control environment (400-450 uatm of CO2), while 'ambon', 'humbug' and 'lemons' exhibit more activity under elevated CO2 (850-1050 uatm of CO2). Simply looking at this graph, it is inconclusive whether the effects of CO2 affects the level of fish activity, which is coherent with the paper's evaluation.    


# ** Statistical testing: 95% Confidence interval, t-statistics, df and p-value **

```{r, stats, echo=TRUE, eval=TRUE}
# Analysing the mean and standard deviation to determine direction of statistical analysis

  # CO2 treatment analysis
treat <- data_n[which(data_n$treatment == "CO2"),] %>% subset(select = -c(loc, animal_id, sl, size))
mean(treat$activity) #29
sd(treat$activity) # 13

  # Control analysis
control <- data_n[which(data_n$treatment == "control"),] %>% subset(select = -c(loc, animal_id, sl, size))
mean(control$activity) # 28
sd(control$activity) # 13
  # Both groups have the same standard deviation and very similar mean values, we can utilise the 2 sample t test


### METHOD 1: Doing t test to each species individually
ancantho <- data_n[which(data_n$species == "acantho"),] %>% subset(select = -c(loc, animal_id, sl, size))
ambon <- data_n[which(data_n$species == "ambon"),] %>% subset(select = -c(loc, animal_id, sl, size))
lemon <- data_n[which(data_n$species == "lemon"),] %>% subset(select = -c(loc, animal_id, sl, size))
chromis <- data_n[which(data_n$species == "chromis"),] %>% subset(select = -c(loc, animal_id, sl, size))
humbug <- data_n[which(data_n$species == "humbug"),] %>% subset(select = -c(loc, animal_id, sl, size))
whitedams <- data_n[which(data_n$species == "whitedams"),] %>% subset(select = -c(loc, animal_id, sl, size))

test_ancantho <- t.test(ancantho$activity ~ ancantho$treatment, var.equal = T)
test_ancantho <- test_ancantho[c(1:5)]
  # Difference in mean = 2
  # 95% confidence interval = -4.9 to 1.6
  # t statistic = -1
  # df = 174
  # p-value = 0.3
test_ambon <- t.test(ambon$activity ~ ambon$treatment, var.equal = T)
test_ambon <- test_ambon[c(1:5)]
  # Difference in mean = 1
  # 95% confidence interval = -6.2 to 8.3
  # t statistic = 0.3
  # df = 41
  # p-value = 0.8
test_lemon <- t.test(lemon$activity ~ lemon$treatment, var.equal = T)
test_lemon <- test_lemon[c(1:5)]
  # Difference in mean = 6
  # 95% confidence interval = -0.7 to 13.2
  # t statistic = 2
  # df = 47
  # p-value = 0.08
test_chromis <- t.test(chromis$activity ~ chromis$treatment, var.equal = T)
test_chromis <- ttest_chromis[c(1:5)]
  # Difference in mean = 1
  # 95% confidence interval = -8.4 to 5.7
  # t statistic = -0.4
  # df = 32
  # p-value = 0.7
test_humbug <- t.test(humbug$activity ~ humbug$treatment, var.equal = T)
test_humbug <- test_humbug[c(1:5)]
  # Difference in mean = 5
  # 95% confidence interval = 0.82 to 9.92
  # t statistic = 2
  # df = 125
  # p-value = 0.02
test_whitedams <- t.test(whitedams$activity ~ whitedams$treatment, var.equal = T) 
test_whitedams <- test_whitedams[c(1:5)]
  # Difference in mean = 3
  # 95% confidence interval = -5.9 to 1.6
  # t statistic = -1
  # df = 119
  # p-value = 0.3


### METHOD 2: ANOVA table to assess overall differences
mod1 <- (lm(activity ~ treatment, data = data_n))
summary(mod1)
```

To do statistical analysis, we first have to look at the properties of the dataset to find which method would be most accurate for our test case. The mean and standard deviation for the treatment and control groups are 29, 13 and 28, 13 respectively. Because both groups have the same standard deviation (13) and very similar mean values (29 and 28), we can utilise the 2 sample t test.

A 2 sample t test evaluates whether the difference between both group's responses are statistically significant or not. This test provides a test statistic which follows the student T distribution under the null hypothesis. In our test case, the null hypothesis states that there is no statistical significance between the population means, while the alternative states that there is.

H_0 : There is no statistical significance between the treatment and control population's mean
H_A : The difference of group means is not 0

One method of further analysis is looking at the fish behaviour at different living conditions depending on each species. As such, we can extract all values from the same species type and use `r <t.test>` to plot fish activity against treatment. Using the default significance level (a) of 0.05, we will observe its relationship with the p-value. The 95% confidence interval tells us that we are 95% confident the true population mean falls within a lower and upper bound. If the p-value is smaller than the significance, it is safe to reject the null hypothesis, meaning there is a statistical significance between the true population mean of control and treatment group. "humbug" is the only one which exhibit this behaviour, while the other fish species exhibit p-values larger than 0.05, therefore we fail to reject the null. Meaning, 4 of the 5 fish species does not show statistical significant difference in activity depending on CO2 levels. 

The second method involves ANOVA for a similar statistical approach. It shows the degree of statistical significance between CO2 (Intercept) and control. The estimate for CO2 is 28.742 while the control group decreases its activity by 0.956 relative to CO2. CO2 has a very low p-value, suggesting statistical significance and a low probability of it occurring by chance. However, the p-value of control is 0.38 which is larger than 0.05. This suggests that we fail to reject the null and shows the overall statistical difference in activity between control and treatment is insignificant, while disregarding species type. 
