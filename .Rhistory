knitr::opts_chunk$set(echo = TRUE)
options(digits=2)
# Install a load of packages that we'll use. I'll show you a shortcut that I love to use. Try using the p_load function in the "pacman" package. p_load will execute both the install.packages and library commands in one shot so they only need to be used once to install pacman itself.
install.packages("pacman", repos = "http://cran.us.r-project.org")
library(pacman)
# Install bookdown for rendering because we'll need this. While we're at it, lets also install /load the tidyverse
p_load(bookdown, tidyverse, ggforce, flextable, latex2exp, png, magick) # basically just list all the packages you want here
```{r, answer1, echo=FALSE, eval = FALSE}
Because if multiple people work on the file on the same time, it creates multiple versions of it, but could produce errors. It is a public repository as well, hence it is easy to lose workings. Others can edit the file so can be bad.
Because if multiple people work on the file on the same time, it creates multiple versions of it, but could produce errors. It is a public repository as well, hence it is easy to lose workings. Others can edit the file so can be bad.
getwd()
getwd()
knitr::opts_chunk$set(echo = TRUE)
options(digits=2)
path <- "C:/Users/Denise Tsoi/OneDrive/Documents/GitHub/3207_Workshop_6"
data <- read_csv(path)
path <- "C:/Users/Denise Tsoi/OneDrive/Documents/GitHub/3207_Workshop_6/Git amp; GitHub Workshop Materials-20220902/OA_activitydat_20190302_BIOL3207.csv"
data <- read_csv(path)
data %>% filter(!(is.na))
View(data)
data %>% filter(!(is.na(data)))
na.omit(data)
filter(!(is.na(data)))
filter((is.na(data)))
is.na(data)
!(is.na(data))
filter(!(is.na(data)), preserve = F)
filter(is.na(data), preserve = F)
type(data)
class(data)
na.omit(data)
filter(is.na(data.frame(data)), preserve = F)
is.na(data)
is.na(data$activity & data$animal_id)
filter(is.na(data$activity & data$animal_id))
filter(is.na(data$activity & data$animal_id), perserve = F)
na.omit(data)
# Drop irrelevant columns
data_n <- data[ -c(...1, comment)]
# Drop irrelevant columns
data_n <- data[ -c("...1", "comment")]
# Drop irrelevant columns
data_n <- data[ -c("...1", "comment"),]
# Drop irrelevant columns
data_n <- data[, -c("...1", "comment")]
# Drop irrelevant columns
data_n <- subset(data, select = -c("...1", "comment"))
# Drop irrelevant columns
data_n <- subset(data, select = -c(...1, comment))
# Check spelling in species and treatment but also generate a summary table
table(data$species)
table(data$treatment)
# Check spelling in species and treatment but also generate a summary table
table(data$species)
# Check spelling in species and treatment but also generate a summary table
table(data$species) #Doesnt seem to have any spelling mistakes
table(data$treatment) #Doesnt seem to have any spelling mistakes
data_n %>% group_by(species) %>% summarise (mean())
data_n %>% group_by(species) %>% summarise (mean(treatment))
data_n %>% group_by(species) %>% summarise (mean(species))
# Use flextable to render the summary table in a tidy format
install.packages("flextable")
install.packages("flextable")
knitr::opts_chunk$set(echo = TRUE)
options(digits=2)
data_n %>% group_by(species & treatment)
# Check spelling in species and treatment but also generate a summary table
library(tidyverse)
data_n %>% group_by(species & treatment)
data_n %>% group_by(species)
data_n %>% group_by(species) %>% group_by(treatment)
goup_by(data_n$species & data_n$treatment)
goup_by(data_n$treatment)
group_by(data_n$treatment)
data_n %>%  group_by(treatment)
data_n %>%  group_by(treatment == "CO2")
data_n %>%  group_by(treatment == "CO2") %>% mean(species == "ambon")
# Drop irrelevant columns
data_n <- subset(data, select = -c(...1, comment))
data_n
data <- na.omit(data)
# Drop irrelevant columns
data_n <- subset(data, select = -c(...1, comment))
table(data$animal_id)
unique <- filter(table(data$animal_id == "1"), preserve = T)
unique <- filter(data$animal_id == "1", preserve = T)
unique <- keep(data$animal_id == "1")
unique <- data_n[!duplicate(data_n[,"animal_id"]),]
unique <- data_n[!duplicated(data_n[,"animal_id"]),]
unique
group_by(unique$treatment)
unique %>%  group_by(treatment == "CO2") %>% mean(species == "ambon")
unique %>%  group_by(treatment == "CO2")
unique %>%  group_by(treatment, species)
unique %>% group_by(species, treatment)
unique %>% group_by(species, treatment) %>% summarise(mean=mean(activity), standard_error = sqrt(var(activty) / length(activity)), sample_size = length(activity))
unique %>% group_by(species, treatment) %>% summarise(mean=mean(activity), n = n(activity), se = sd(activity) / sqrt(n))
unique %>% group_by(species, treatment) %>% summarise(mean=mean(activity),
n = length(activity),
se = sd(activity) / sqrt(n))
library(flextable)
data_n <- group_by(species, treatment) %>% summarise(mean=mean(activity),
n = length(activity),
se = sd(activity) / sqrt(n))
data_n
data_n <- group_by(species, treatment) %>% summarise(mean=mean(activity),
n = length(activity),
se = sd(activity) / sqrt(n))
data_n %>% group_by(species, treatment) %>% summarise(mean=mean(activity),
n = length(activity),
se = sd(activity) / sqrt(n))
table(data$species) #Doesnt seem to have any spelling mistakes
data_n
data_n %>% group_by(species, treatment) %>% summarise(mean = mean(activity),
n = length(activity),
se = sd(activity) / sqrt(n))
data_n
table(data_n$animal_id)
unique <- data_n[duplicated(data_n[,"animal_id"]),] #Kept unique values
unique
unique <- data_n[!duplicated(data_n[,"animal_id"]),] #Kept unique values
unique
